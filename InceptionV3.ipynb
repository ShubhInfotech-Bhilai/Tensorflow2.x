{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionV3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPNWLdECD9blzSCOgtZDxSj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adarsh415/Tensorflow2.x/blob/master/InceptionV3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9vGLv3-oGWK",
        "colab_type": "code",
        "outputId": "124dd2b4-eb84-4dc4-b300-be0d004ea622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as k\n",
        "from tensorflow.keras import metrics, datasets, layers, models, optimizers\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3nY3S9boqXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "  (Xtrain, Ytrain), (Xtest, Ytest) = datasets.cifar10.load_data()\n",
        "  Xtrain, Xtest = Xtrain.astype(np.float32)/255.0, Xtest.astype(np.float32)/255.0\n",
        "  trainDS = tf.data.Dataset.from_tensor_slices((Xtrain, Ytrain))\n",
        "  trainDS = trainDS.shuffle(50000).batch(64)\n",
        "  testDS = tf.data.Dataset.from_tensor_slices((Xtest, Ytest))\n",
        "  testDS = testDS.batch(64)\n",
        "\n",
        "  return trainDS, testDS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVND_HO8po68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InceptionBlk(models.Model):\n",
        "  def __init__(self,\n",
        "               filter_1x1,\n",
        "               filter_3x3,\n",
        "               reduce_3x3,\n",
        "               filter_5x5,\n",
        "               reduce_5x5,\n",
        "               pool_filter,\n",
        "               kernel_init, bias_init):\n",
        "    super(InceptionBlk, self).__init__(name='InceptionBlk')\n",
        "\n",
        "    self.conv1x1 = layers.Conv2D(filter_1x1, kernel_size=1, strides = 1, padding='same',activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
        "    self.conv3x3_reduce =  layers.Conv2D(reduce_3x3, kernel_size=1, strides = 1, padding='same',activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
        "    self.conv3x3 = layers.Conv2D(filter_3x3, kernel_size=3, strides = 1, padding='same',activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
        "    self.conv5x5_reduce = layers.Conv2D(reduce_5x5,kernel_size=1, strides = 1, padding='same',activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
        "    self.conv5x5 = layers.Conv2D(filter_5x5, kernel_size=3, strides = 1, padding='same',activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
        "    self.max5x5 = layers.MaxPool2D(pool_size=(5,5), strides=1, padding='same')\n",
        "    self.conv1x1_max = layers.Conv2D(pool_filter, kernel_size=1, strides = 1, padding='same',activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
        "\n",
        "  def call(self, x):\n",
        "\n",
        "    x_1 = self.conv1x1(x)\n",
        "\n",
        "    x_3 = self.conv3x3_reduce(x)\n",
        "    x_3 = self.conv3x3(x_3)\n",
        "\n",
        "    x_5 = self.conv5x5_reduce(x)\n",
        "    x_5 = self.conv5x5(x_5)\n",
        "\n",
        "    x_pool = self.max5x5(x)\n",
        "    x_pool = self.conv1x1_max(x_pool)\n",
        "\n",
        "    return layers.concatenate([x_1, x_3, x_5, x_pool])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc3Ytgxb00HM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "class InceptionV3(models.Model):\n",
        "  def __init__(self, kernel_init, bias_init, aux=True):\n",
        "    super(InceptionV3, self).__init__(self)\n",
        "    self.kernel_init = kernel_init\n",
        "    self.bias_init = bias_init\n",
        "    self.aux = aux\n",
        "    self._InceptionOutput = namedtuple(\"InceptionOutputs\", [\"logits\", \"aux_logits1\", \"aux_logits2\"])\n",
        "\n",
        "\n",
        "  def call(self, x, training=True, aux=True):\n",
        "\n",
        "    # first conv block\n",
        "    block_1 = layers.Conv2D(64, kernel_size=7, strides=2, padding='same', activation='relu', kernel_initializer=self.kernel_init, bias_initializer=self.bias_init)(x)\n",
        "    block_1 = layers.MaxPool2D(pool_size=3, strides=2, padding='same')(block_1)\n",
        "    block_1 = layers.BatchNormalization(trainable=training)(block_1)\n",
        "\n",
        "    # second conv block\n",
        "    block_2 = layers.Conv2D(64, kernel_size=1, strides=1, padding='same', activation='relu', kernel_initializer=self.kernel_init, bias_initializer=self.bias_init)(x)\n",
        "    block_2 = layers.Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu', kernel_initializer=self.kernel_init, bias_initializer=self.bias_init)(x)\n",
        "    block_2 = layers.BatchNormalization(trainable=training)(block_2)\n",
        "    block_2 = layers.MaxPool2D(pool_size=3, strides=2, padding='same')(block_2)\n",
        "\n",
        "    # inception block 1a\n",
        "    inception_1a = InceptionBlk(filter_1x1=64,\n",
        "                                filter_3x3=128,\n",
        "                                reduce_3x3=96,\n",
        "                                filter_5x5=32,\n",
        "                                reduce_5x5=16,\n",
        "                                pool_filter=32,\n",
        "                                kernel_init=self.kernel_init,\n",
        "                                bias_init= self.bias_init)(block_2)\n",
        "    # inception block 2a\n",
        "    inception_2a = InceptionBlk(filter_1x1=128,\n",
        "                                filter_3x3=192,\n",
        "                                reduce_3x3=128,\n",
        "                                filter_5x5=96,\n",
        "                                reduce_5x5=32,\n",
        "                                pool_filter=64,\n",
        "                                kernel_init=self.kernel_init,\n",
        "                                bias_init= self.bias_init)(inception_1a)\n",
        "\n",
        "    # max pool layer\n",
        "    pool_1 = layers.MaxPool2D(pool_size=3, strides=2, padding='same')(inception_2a)\n",
        "\n",
        "    # inception block 3a\n",
        "    inception_3a = InceptionBlk(filter_1x1=192,\n",
        "                                filter_3x3=208,\n",
        "                                reduce_3x3=96,\n",
        "                                filter_5x5=48,\n",
        "                                reduce_5x5=16,\n",
        "                                pool_filter=64,\n",
        "                                kernel_init=self.kernel_init,\n",
        "                                bias_init= self.bias_init)(pool_1)\n",
        "\n",
        "    # first softmax layer\n",
        "    soft_1 = layers.AveragePooling2D(pool_size=5, strides=3, padding='valid')(inception_3a)\n",
        "    soft_1 = layers.Conv2D(128, kernel_size=1, strides=1, padding='same', activation='relu', kernel_initializer=self.kernel_init, bias_initializer=self.bias_init)(soft_1)\n",
        "    soft_1 = layers.Flatten()(soft_1)\n",
        "    soft_1 = layers.Dense(1024, activation='relu')(soft_1)\n",
        "    soft_1 = layers.Dropout(0.7)(soft_1,training=training)\n",
        "    soft_1 = layers.Dense(10, activation='softmax')(soft_1)\n",
        "    \n",
        "\n",
        "    #inception block 4a\n",
        "    inception_4a = InceptionBlk(filter_1x1=160,\n",
        "                                filter_3x3=224,\n",
        "                                reduce_3x3=112,\n",
        "                                filter_5x5=64,\n",
        "                                reduce_5x5=24,\n",
        "                                pool_filter=64,\n",
        "                                kernel_init=self.kernel_init,\n",
        "                                bias_init= self.bias_init)(inception_3a)\n",
        "\n",
        "    #inception block 5a\n",
        "    inception_5a = InceptionBlk(filter_1x1=128,\n",
        "                                filter_3x3=256,\n",
        "                                reduce_3x3=128,\n",
        "                                filter_5x5=64,\n",
        "                                reduce_5x5=24,\n",
        "                                pool_filter=64,\n",
        "                                kernel_init=self.kernel_init,\n",
        "                                bias_init= self.bias_init)(inception_4a)\n",
        "\n",
        "    #inception block 6a\n",
        "    inception_6a = InceptionBlk(filter_1x1=112,\n",
        "                                filter_3x3=288,\n",
        "                                reduce_3x3=144,\n",
        "                                filter_5x5=64,\n",
        "                                reduce_5x5=32,\n",
        "                                pool_filter=64,\n",
        "                                kernel_init=self.kernel_init,\n",
        "                                bias_init= self.bias_init)(inception_5a)\n",
        "\n",
        "\n",
        "    #second softmax layer\n",
        "    soft_2 = layers.AveragePooling2D(pool_size=5, strides=3, padding='valid')(inception_6a)\n",
        "    soft_2 = layers.Conv2D(128, kernel_size=1, strides=1, padding='same', activation='relu', kernel_initializer=self.kernel_init, bias_initializer=self.bias_init)(soft_2)\n",
        "    soft_2 = layers.Flatten()(soft_2)\n",
        "    soft_2 = layers.Dense(1024, activation='relu')(soft_2)\n",
        "    soft_2 = layers.Dropout(0.7)(soft_2, training=training)\n",
        "    soft_2 = layers.Dense(10, activation='softmax')(soft_2)\n",
        "\n",
        "    #inception block 7a\n",
        "    inception_7a = InceptionBlk(filter_1x1=256,\n",
        "                                filter_3x3=320,\n",
        "                                reduce_3x3=160,\n",
        "                                filter_5x5=128,\n",
        "                                reduce_5x5=32,\n",
        "                                pool_filter=128,\n",
        "                                kernel_init=self.kernel_init,\n",
        "                                bias_init= self.bias_init)(inception_6a)\n",
        "\n",
        "    # max pool layer\n",
        "    pool_2 = layers.MaxPool2D(pool_size=3, strides=2, padding='same')(inception_7a)\n",
        "    \n",
        "    #inception block 8a\n",
        "    inception_8a = InceptionBlk(filter_1x1=256,\n",
        "                                filter_3x3=320,\n",
        "                                reduce_3x3=160,\n",
        "                                filter_5x5=128,\n",
        "                                reduce_5x5=32,\n",
        "                                pool_filter=128,\n",
        "                                kernel_init=self.kernel_init,\n",
        "                                bias_init= self.bias_init)(pool_2)\n",
        "    \n",
        "    #inception block 9a\n",
        "    inception_9a = InceptionBlk(filter_1x1=384,\n",
        "                                filter_3x3=384,\n",
        "                                reduce_3x3=192,\n",
        "                                filter_5x5=128,\n",
        "                                reduce_5x5=48,\n",
        "                                pool_filter=128,\n",
        "                                kernel_init=self.kernel_init,\n",
        "                                bias_init= self.bias_init)(inception_8a)\n",
        "\n",
        "    #third softmax layer\n",
        "    #soft_3 = layers.AveragePooling2D(pool_size=7, strides=1, padding='valid')(inception_9a)\n",
        "    #soft_3 = layers.AveragePooling2D()(inception_9a)\n",
        "    soft_3 = layers.GlobalAveragePooling2D()(inception_9a)\n",
        "    soft_3 = layers.Dropout(0.4)(soft_3, training=training)\n",
        "    soft_3 = layers.Flatten()(soft_3)\n",
        "    soft_3 = layers.Dense(1024, activation='relu')(soft_3)\n",
        "    soft_3 = layers.Dense(10, activation='softmax')(soft_3)\n",
        "\n",
        "    if self.aux and aux:\n",
        "      return self._InceptionOutput(soft_3,soft_1,soft_2)\n",
        "    else:\n",
        "      return soft_3\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY-5iOncEfKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    n_epoch = 100\n",
        "    train_ds, test_ds = load_data()\n",
        "\n",
        "    optimizer = optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "    kernel_init = k.initializers.he_normal()\n",
        "    bias_init = k.initializers.he_normal()\n",
        "    model3 = InceptionV3(kernel_init,bias_init)\n",
        "\n",
        "    # acc = metrics.CategoricalAccuracy()\n",
        "    acc = metrics.Accuracy()\n",
        "    lossfn = tf.keras.losses.CategoricalCrossentropy()\n",
        "    \n",
        "    for epoch in range(n_epoch):\n",
        "        losses = 0.0\n",
        "        accuracy = 0.0\n",
        "        #step = 0\n",
        "        for step, (x,y) in enumerate(train_ds):\n",
        "\n",
        "            with tf.GradientTape() as tape3:\n",
        "              logits3 = model3(x)\n",
        "              #print('logit shape', logits3.shape)\n",
        "              loss2 = lossfn(tf.one_hot(y,10),logits3.aux_logits2)\n",
        "              loss1 = lossfn(tf.one_hot(y,10),logits3.aux_logits1)\n",
        "              loss3 = lossfn(tf.one_hot(y,10),logits3.logits)\n",
        "              #acc.update_state(tf.one_hot(y,10), logits3) this should be used with CategoricalAccuracy()\n",
        "              acc.update_state(y, tf.argmax(logits3.logits, axis=1, output_type=tf.int32))\n",
        "              losses = 0.25*loss2+0.25*loss1+0.5*loss3\n",
        "\n",
        "            grads3 = tape3.gradient(losses, model3.trainable_variables)\n",
        "            grads3 = [tf.clip_by_norm(g, 15) for g in grads3]\n",
        "            optimizer.apply_gradients(zip(grads3, model3.trainable_variables))\n",
        "\n",
        "            \n",
        "            if step%1000 == 0:\n",
        "                #accuracy = compute_accuracy(logits, tf.cast(y, tf.int64))\n",
        "                #print(f' accuracy in epoch {epoch} after steps {step} is: {accuracy.numpy()}')\n",
        "\n",
        "                print(f' accuracy in epoch {epoch} after steps {step} is: {acc.result().numpy()}')\n",
        "                acc.reset_states()\n",
        "\n",
        "                #print(f' Loss in epoch {epoch} after steps {step} is: {losses}')\n",
        "                print(f' Loss for main model3 in epoch {epoch} after steps {step} is: {losses.numpy()}')\n",
        "                \n",
        "\n",
        "        print(f'loss after epoch {epoch} is {losses.numpy()}')\n",
        "\n",
        "\n",
        "\n",
        "    print(f'final training accuracy is {acc.result().numpy()}')\n",
        "    acc.reset_states()\n",
        "\n",
        "\n",
        "    #model.save('VGG16', save_format='tf')\n",
        "    for step, (x, y) in enumerate(test_ds):\n",
        "        logits = model3(x, training=False, aux=False)\n",
        "        acc.update_state(y, tf.argmax(logits, axis=1, output_type=tf.int32))\n",
        "            \n",
        "    print(f'test accuracy is {acc.result().numpy()}')\n",
        "    acc.reset_states()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3sU-4p6Fu9Z",
        "colab_type": "code",
        "outputId": "e77bb8f0-ba23-4456-9422-d774e86e8710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 13s 0us/step\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            " accuracy in epoch 0 after steps 0 is: 0.171875\n",
            " Loss for main model3 in epoch 0 after steps 0 is: 2.877323627471924\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "loss after epoch 0 is 3.298762798309326\n",
            " accuracy in epoch 1 after steps 0 is: 0.09836000204086304\n",
            " Loss for main model3 in epoch 1 after steps 0 is: 2.9629969596862793\n",
            "loss after epoch 1 is 2.675048589706421\n",
            " accuracy in epoch 2 after steps 0 is: 0.09950000047683716\n",
            " Loss for main model3 in epoch 2 after steps 0 is: 3.1156768798828125\n",
            "loss after epoch 2 is 3.1732945442199707\n",
            " accuracy in epoch 3 after steps 0 is: 0.09774000197649002\n",
            " Loss for main model3 in epoch 3 after steps 0 is: 2.8723647594451904\n",
            "loss after epoch 3 is 2.95731258392334\n",
            " accuracy in epoch 4 after steps 0 is: 0.09905999898910522\n",
            " Loss for main model3 in epoch 4 after steps 0 is: 3.5881261825561523\n",
            "loss after epoch 4 is 2.803189992904663\n",
            " accuracy in epoch 5 after steps 0 is: 0.09973999857902527\n",
            " Loss for main model3 in epoch 5 after steps 0 is: 2.6588377952575684\n",
            "loss after epoch 5 is 2.79373836517334\n",
            " accuracy in epoch 6 after steps 0 is: 0.09877999871969223\n",
            " Loss for main model3 in epoch 6 after steps 0 is: 2.79545521736145\n",
            "loss after epoch 6 is 2.814197540283203\n",
            " accuracy in epoch 7 after steps 0 is: 0.10063999891281128\n",
            " Loss for main model3 in epoch 7 after steps 0 is: 2.739281177520752\n",
            "loss after epoch 7 is 2.970355272293091\n",
            " accuracy in epoch 8 after steps 0 is: 0.09870000183582306\n",
            " Loss for main model3 in epoch 8 after steps 0 is: 2.75868558883667\n",
            "loss after epoch 8 is 3.284911632537842\n",
            " accuracy in epoch 9 after steps 0 is: 0.09798000007867813\n",
            " Loss for main model3 in epoch 9 after steps 0 is: 2.8854446411132812\n",
            "loss after epoch 9 is 2.835853099822998\n",
            " accuracy in epoch 10 after steps 0 is: 0.1025800034403801\n",
            " Loss for main model3 in epoch 10 after steps 0 is: 3.452515125274658\n",
            "loss after epoch 10 is 3.0864086151123047\n",
            " accuracy in epoch 11 after steps 0 is: 0.1011200025677681\n",
            " Loss for main model3 in epoch 11 after steps 0 is: 2.909818649291992\n",
            "loss after epoch 11 is 3.0424740314483643\n",
            " accuracy in epoch 12 after steps 0 is: 0.10130000114440918\n",
            " Loss for main model3 in epoch 12 after steps 0 is: 2.6248879432678223\n",
            "loss after epoch 12 is 3.263537883758545\n",
            " accuracy in epoch 13 after steps 0 is: 0.10035999864339828\n",
            " Loss for main model3 in epoch 13 after steps 0 is: 2.896749973297119\n",
            "loss after epoch 13 is 2.646475315093994\n",
            " accuracy in epoch 14 after steps 0 is: 0.10266000032424927\n",
            " Loss for main model3 in epoch 14 after steps 0 is: 2.7405810356140137\n",
            "loss after epoch 14 is 2.8075335025787354\n",
            " accuracy in epoch 15 after steps 0 is: 0.10249999910593033\n",
            " Loss for main model3 in epoch 15 after steps 0 is: 2.5639140605926514\n",
            "loss after epoch 15 is 2.9383955001831055\n",
            " accuracy in epoch 16 after steps 0 is: 0.09876000136137009\n",
            " Loss for main model3 in epoch 16 after steps 0 is: 3.1001062393188477\n",
            "loss after epoch 16 is 2.7505292892456055\n",
            " accuracy in epoch 17 after steps 0 is: 0.09876000136137009\n",
            " Loss for main model3 in epoch 17 after steps 0 is: 3.5409250259399414\n",
            "loss after epoch 17 is 2.71932053565979\n",
            " accuracy in epoch 18 after steps 0 is: 0.09860000014305115\n",
            " Loss for main model3 in epoch 18 after steps 0 is: 2.788879871368408\n",
            "loss after epoch 18 is 3.0950613021850586\n",
            " accuracy in epoch 19 after steps 0 is: 0.10075999796390533\n",
            " Loss for main model3 in epoch 19 after steps 0 is: 3.0626940727233887\n",
            "loss after epoch 19 is 3.070664167404175\n",
            " accuracy in epoch 20 after steps 0 is: 0.10040000081062317\n",
            " Loss for main model3 in epoch 20 after steps 0 is: 3.165419101715088\n",
            "loss after epoch 20 is 3.4813547134399414\n",
            " accuracy in epoch 21 after steps 0 is: 0.10044000297784805\n",
            " Loss for main model3 in epoch 21 after steps 0 is: 3.425784111022949\n",
            "loss after epoch 21 is 2.787553310394287\n",
            " accuracy in epoch 22 after steps 0 is: 0.09907999634742737\n",
            " Loss for main model3 in epoch 22 after steps 0 is: 3.277712345123291\n",
            "loss after epoch 22 is 3.066317081451416\n",
            " accuracy in epoch 23 after steps 0 is: 0.10119999945163727\n",
            " Loss for main model3 in epoch 23 after steps 0 is: 2.9796371459960938\n",
            "loss after epoch 23 is 2.9753236770629883\n",
            " accuracy in epoch 24 after steps 0 is: 0.09650000184774399\n",
            " Loss for main model3 in epoch 24 after steps 0 is: 2.760977029800415\n",
            "loss after epoch 24 is 2.8089022636413574\n",
            " accuracy in epoch 25 after steps 0 is: 0.09932000190019608\n",
            " Loss for main model3 in epoch 25 after steps 0 is: 2.884396553039551\n",
            "loss after epoch 25 is 3.1932315826416016\n",
            " accuracy in epoch 26 after steps 0 is: 0.09827999770641327\n",
            " Loss for main model3 in epoch 26 after steps 0 is: 3.2837953567504883\n",
            "loss after epoch 26 is 2.8296332359313965\n",
            " accuracy in epoch 27 after steps 0 is: 0.09939999878406525\n",
            " Loss for main model3 in epoch 27 after steps 0 is: 2.6150918006896973\n",
            "loss after epoch 27 is 3.112031936645508\n",
            " accuracy in epoch 28 after steps 0 is: 0.09815999865531921\n",
            " Loss for main model3 in epoch 28 after steps 0 is: 3.0045485496520996\n",
            "loss after epoch 28 is 2.652146577835083\n",
            " accuracy in epoch 29 after steps 0 is: 0.09973999857902527\n",
            " Loss for main model3 in epoch 29 after steps 0 is: 3.5267763137817383\n",
            "loss after epoch 29 is 3.028286933898926\n",
            " accuracy in epoch 30 after steps 0 is: 0.09845999628305435\n",
            " Loss for main model3 in epoch 30 after steps 0 is: 2.8359367847442627\n",
            "loss after epoch 30 is 2.861884117126465\n",
            " accuracy in epoch 31 after steps 0 is: 0.10013999789953232\n",
            " Loss for main model3 in epoch 31 after steps 0 is: 3.218289375305176\n",
            "loss after epoch 31 is 2.757704019546509\n",
            " accuracy in epoch 32 after steps 0 is: 0.09932000190019608\n",
            " Loss for main model3 in epoch 32 after steps 0 is: 2.6934351921081543\n",
            "loss after epoch 32 is 2.642350196838379\n",
            " accuracy in epoch 33 after steps 0 is: 0.09926000237464905\n",
            " Loss for main model3 in epoch 33 after steps 0 is: 2.7095634937286377\n",
            "loss after epoch 33 is 3.1254212856292725\n",
            " accuracy in epoch 34 after steps 0 is: 0.09960000216960907\n",
            " Loss for main model3 in epoch 34 after steps 0 is: 2.654311180114746\n",
            "loss after epoch 34 is 2.859276294708252\n",
            " accuracy in epoch 35 after steps 0 is: 0.1019200012087822\n",
            " Loss for main model3 in epoch 35 after steps 0 is: 2.6937873363494873\n",
            "loss after epoch 35 is 3.1984968185424805\n",
            " accuracy in epoch 36 after steps 0 is: 0.09709999710321426\n",
            " Loss for main model3 in epoch 36 after steps 0 is: 2.677609443664551\n",
            "loss after epoch 36 is 3.409494400024414\n",
            " accuracy in epoch 37 after steps 0 is: 0.09978000074625015\n",
            " Loss for main model3 in epoch 37 after steps 0 is: 2.917036533355713\n",
            "loss after epoch 37 is 2.7606425285339355\n",
            " accuracy in epoch 38 after steps 0 is: 0.09749999642372131\n",
            " Loss for main model3 in epoch 38 after steps 0 is: 2.6259348392486572\n",
            "loss after epoch 38 is 3.443432569503784\n",
            " accuracy in epoch 39 after steps 0 is: 0.1012599989771843\n",
            " Loss for main model3 in epoch 39 after steps 0 is: 3.245244026184082\n",
            "loss after epoch 39 is 3.082357883453369\n",
            " accuracy in epoch 40 after steps 0 is: 0.10208000242710114\n",
            " Loss for main model3 in epoch 40 after steps 0 is: 2.9616827964782715\n",
            "loss after epoch 40 is 2.8757481575012207\n",
            " accuracy in epoch 41 after steps 0 is: 0.10028000175952911\n",
            " Loss for main model3 in epoch 41 after steps 0 is: 3.136707305908203\n",
            "loss after epoch 41 is 3.153330087661743\n",
            " accuracy in epoch 42 after steps 0 is: 0.10198000073432922\n",
            " Loss for main model3 in epoch 42 after steps 0 is: 3.1223578453063965\n",
            "loss after epoch 42 is 3.018953323364258\n",
            " accuracy in epoch 43 after steps 0 is: 0.10320000350475311\n",
            " Loss for main model3 in epoch 43 after steps 0 is: 2.9681661128997803\n",
            "loss after epoch 43 is 2.729435920715332\n",
            " accuracy in epoch 44 after steps 0 is: 0.09842000156641006\n",
            " Loss for main model3 in epoch 44 after steps 0 is: 2.734705924987793\n",
            "loss after epoch 44 is 2.9279494285583496\n",
            " accuracy in epoch 45 after steps 0 is: 0.10292000323534012\n",
            " Loss for main model3 in epoch 45 after steps 0 is: 2.8928887844085693\n",
            "loss after epoch 45 is 2.6940789222717285\n",
            " accuracy in epoch 46 after steps 0 is: 0.09845999628305435\n",
            " Loss for main model3 in epoch 46 after steps 0 is: 2.815662384033203\n",
            "loss after epoch 46 is 3.689401149749756\n",
            " accuracy in epoch 47 after steps 0 is: 0.10159999877214432\n",
            " Loss for main model3 in epoch 47 after steps 0 is: 2.7612218856811523\n",
            "loss after epoch 47 is 2.9011168479919434\n",
            " accuracy in epoch 48 after steps 0 is: 0.10023999959230423\n",
            " Loss for main model3 in epoch 48 after steps 0 is: 3.184676170349121\n",
            "loss after epoch 48 is 2.820479393005371\n",
            " accuracy in epoch 49 after steps 0 is: 0.10085999965667725\n",
            " Loss for main model3 in epoch 49 after steps 0 is: 3.042659044265747\n",
            "loss after epoch 49 is 2.8362629413604736\n",
            " accuracy in epoch 50 after steps 0 is: 0.0972599983215332\n",
            " Loss for main model3 in epoch 50 after steps 0 is: 2.8680639266967773\n",
            "loss after epoch 50 is 3.1478514671325684\n",
            " accuracy in epoch 51 after steps 0 is: 0.09926000237464905\n",
            " Loss for main model3 in epoch 51 after steps 0 is: 3.060739517211914\n",
            "loss after epoch 51 is 2.8139448165893555\n",
            " accuracy in epoch 52 after steps 0 is: 0.10000000149011612\n",
            " Loss for main model3 in epoch 52 after steps 0 is: 3.1020219326019287\n",
            "loss after epoch 52 is 3.1923437118530273\n",
            " accuracy in epoch 53 after steps 0 is: 0.10053999722003937\n",
            " Loss for main model3 in epoch 53 after steps 0 is: 2.842844009399414\n",
            "loss after epoch 53 is 2.9882540702819824\n",
            " accuracy in epoch 54 after steps 0 is: 0.10047999769449234\n",
            " Loss for main model3 in epoch 54 after steps 0 is: 3.4271769523620605\n",
            "loss after epoch 54 is 3.040414333343506\n",
            " accuracy in epoch 55 after steps 0 is: 0.09995999932289124\n",
            " Loss for main model3 in epoch 55 after steps 0 is: 2.7517709732055664\n",
            "loss after epoch 55 is 2.854889392852783\n",
            " accuracy in epoch 56 after steps 0 is: 0.10288000106811523\n",
            " Loss for main model3 in epoch 56 after steps 0 is: 3.351980209350586\n",
            "loss after epoch 56 is 2.9183614253997803\n",
            " accuracy in epoch 57 after steps 0 is: 0.09764000028371811\n",
            " Loss for main model3 in epoch 57 after steps 0 is: 2.90024471282959\n",
            "loss after epoch 57 is 2.7662065029144287\n",
            " accuracy in epoch 58 after steps 0 is: 0.09784000366926193\n",
            " Loss for main model3 in epoch 58 after steps 0 is: 2.998185634613037\n",
            "loss after epoch 58 is 2.8573110103607178\n",
            " accuracy in epoch 59 after steps 0 is: 0.10040000081062317\n",
            " Loss for main model3 in epoch 59 after steps 0 is: 2.724179744720459\n",
            "loss after epoch 59 is 2.8426098823547363\n",
            " accuracy in epoch 60 after steps 0 is: 0.09666000306606293\n",
            " Loss for main model3 in epoch 60 after steps 0 is: 2.717170476913452\n",
            "loss after epoch 60 is 3.204895496368408\n",
            " accuracy in epoch 61 after steps 0 is: 0.10143999755382538\n",
            " Loss for main model3 in epoch 61 after steps 0 is: 3.494741439819336\n",
            "loss after epoch 61 is 2.895200252532959\n",
            " accuracy in epoch 62 after steps 0 is: 0.09991999715566635\n",
            " Loss for main model3 in epoch 62 after steps 0 is: 2.866300344467163\n",
            "loss after epoch 62 is 2.76282000541687\n",
            " accuracy in epoch 63 after steps 0 is: 0.09972000122070312\n",
            " Loss for main model3 in epoch 63 after steps 0 is: 2.9597434997558594\n",
            "loss after epoch 63 is 3.1367602348327637\n",
            " accuracy in epoch 64 after steps 0 is: 0.10146000236272812\n",
            " Loss for main model3 in epoch 64 after steps 0 is: 3.1485071182250977\n",
            "loss after epoch 64 is 2.7505011558532715\n",
            " accuracy in epoch 65 after steps 0 is: 0.09942000359296799\n",
            " Loss for main model3 in epoch 65 after steps 0 is: 2.949103355407715\n",
            "loss after epoch 65 is 2.8753316402435303\n",
            " accuracy in epoch 66 after steps 0 is: 0.0989999994635582\n",
            " Loss for main model3 in epoch 66 after steps 0 is: 3.752647876739502\n",
            "loss after epoch 66 is 2.670292377471924\n",
            " accuracy in epoch 67 after steps 0 is: 0.10028000175952911\n",
            " Loss for main model3 in epoch 67 after steps 0 is: 2.8949358463287354\n",
            "loss after epoch 67 is 3.295884609222412\n",
            " accuracy in epoch 68 after steps 0 is: 0.09895999729633331\n",
            " Loss for main model3 in epoch 68 after steps 0 is: 3.061633348464966\n",
            "loss after epoch 68 is 3.0543012619018555\n",
            " accuracy in epoch 69 after steps 0 is: 0.09877999871969223\n",
            " Loss for main model3 in epoch 69 after steps 0 is: 2.8227052688598633\n",
            "loss after epoch 69 is 3.1544411182403564\n",
            " accuracy in epoch 70 after steps 0 is: 0.10051999986171722\n",
            " Loss for main model3 in epoch 70 after steps 0 is: 3.1556193828582764\n",
            "loss after epoch 70 is 2.834946632385254\n",
            " accuracy in epoch 71 after steps 0 is: 0.09901999682188034\n",
            " Loss for main model3 in epoch 71 after steps 0 is: 3.0198333263397217\n",
            "loss after epoch 71 is 2.6769375801086426\n",
            " accuracy in epoch 72 after steps 0 is: 0.10078000277280807\n",
            " Loss for main model3 in epoch 72 after steps 0 is: 3.39247989654541\n",
            "loss after epoch 72 is 2.902383327484131\n",
            " accuracy in epoch 73 after steps 0 is: 0.09929999709129333\n",
            " Loss for main model3 in epoch 73 after steps 0 is: 2.7666587829589844\n",
            "loss after epoch 73 is 3.1179885864257812\n",
            " accuracy in epoch 74 after steps 0 is: 0.09929999709129333\n",
            " Loss for main model3 in epoch 74 after steps 0 is: 3.329483985900879\n",
            "loss after epoch 74 is 4.036890983581543\n",
            " accuracy in epoch 75 after steps 0 is: 0.09893999993801117\n",
            " Loss for main model3 in epoch 75 after steps 0 is: 3.2556841373443604\n",
            "loss after epoch 75 is 2.923717975616455\n",
            " accuracy in epoch 76 after steps 0 is: 0.10096000134944916\n",
            " Loss for main model3 in epoch 76 after steps 0 is: 2.7075629234313965\n",
            "loss after epoch 76 is 2.762348175048828\n",
            " accuracy in epoch 77 after steps 0 is: 0.09824000298976898\n",
            " Loss for main model3 in epoch 77 after steps 0 is: 3.162426471710205\n",
            "loss after epoch 77 is 3.7150137424468994\n",
            " accuracy in epoch 78 after steps 0 is: 0.10075999796390533\n",
            " Loss for main model3 in epoch 78 after steps 0 is: 2.8680419921875\n",
            "loss after epoch 78 is 2.7260680198669434\n",
            " accuracy in epoch 79 after steps 0 is: 0.09944000095129013\n",
            " Loss for main model3 in epoch 79 after steps 0 is: 2.9857277870178223\n",
            "loss after epoch 79 is 3.4484214782714844\n",
            " accuracy in epoch 80 after steps 0 is: 0.10057999938726425\n",
            " Loss for main model3 in epoch 80 after steps 0 is: 2.9574332237243652\n",
            "loss after epoch 80 is 3.2107772827148438\n",
            " accuracy in epoch 81 after steps 0 is: 0.1017799973487854\n",
            " Loss for main model3 in epoch 81 after steps 0 is: 2.677929639816284\n",
            "loss after epoch 81 is 2.881512403488159\n",
            " accuracy in epoch 82 after steps 0 is: 0.10226000100374222\n",
            " Loss for main model3 in epoch 82 after steps 0 is: 2.8548030853271484\n",
            "loss after epoch 82 is 2.976362705230713\n",
            " accuracy in epoch 83 after steps 0 is: 0.09926000237464905\n",
            " Loss for main model3 in epoch 83 after steps 0 is: 2.6480612754821777\n",
            "loss after epoch 83 is 3.243983507156372\n",
            " accuracy in epoch 84 after steps 0 is: 0.09898000210523605\n",
            " Loss for main model3 in epoch 84 after steps 0 is: 3.1516830921173096\n",
            "loss after epoch 84 is 3.242947578430176\n",
            " accuracy in epoch 85 after steps 0 is: 0.09935999661684036\n",
            " Loss for main model3 in epoch 85 after steps 0 is: 2.9689536094665527\n",
            "loss after epoch 85 is 2.3162484169006348\n",
            " accuracy in epoch 86 after steps 0 is: 0.09898000210523605\n",
            " Loss for main model3 in epoch 86 after steps 0 is: 3.0827200412750244\n",
            "loss after epoch 86 is 2.7956905364990234\n",
            " accuracy in epoch 87 after steps 0 is: 0.09991999715566635\n",
            " Loss for main model3 in epoch 87 after steps 0 is: 2.6838321685791016\n",
            "loss after epoch 87 is 3.4124131202697754\n",
            " accuracy in epoch 88 after steps 0 is: 0.09774000197649002\n",
            " Loss for main model3 in epoch 88 after steps 0 is: 2.7031607627868652\n",
            "loss after epoch 88 is 3.5268635749816895\n",
            " accuracy in epoch 89 after steps 0 is: 0.10063999891281128\n",
            " Loss for main model3 in epoch 89 after steps 0 is: 2.894594669342041\n",
            "loss after epoch 89 is 3.5310654640197754\n",
            " accuracy in epoch 90 after steps 0 is: 0.09960000216960907\n",
            " Loss for main model3 in epoch 90 after steps 0 is: 2.822547435760498\n",
            "loss after epoch 90 is 2.9127907752990723\n",
            " accuracy in epoch 91 after steps 0 is: 0.10093999654054642\n",
            " Loss for main model3 in epoch 91 after steps 0 is: 2.7596404552459717\n",
            "loss after epoch 91 is 3.574901580810547\n",
            " accuracy in epoch 92 after steps 0 is: 0.10035999864339828\n",
            " Loss for main model3 in epoch 92 after steps 0 is: 2.915895938873291\n",
            "loss after epoch 92 is 3.116100311279297\n",
            " accuracy in epoch 93 after steps 0 is: 0.0993800014257431\n",
            " Loss for main model3 in epoch 93 after steps 0 is: 3.054335594177246\n",
            "loss after epoch 93 is 2.8974359035491943\n",
            " accuracy in epoch 94 after steps 0 is: 0.10044000297784805\n",
            " Loss for main model3 in epoch 94 after steps 0 is: 3.5002167224884033\n",
            "loss after epoch 94 is 3.182035446166992\n",
            " accuracy in epoch 95 after steps 0 is: 0.10100000351667404\n",
            " Loss for main model3 in epoch 95 after steps 0 is: 2.7590394020080566\n",
            "loss after epoch 95 is 2.83290958404541\n",
            " accuracy in epoch 96 after steps 0 is: 0.10096000134944916\n",
            " Loss for main model3 in epoch 96 after steps 0 is: 2.9268436431884766\n",
            "loss after epoch 96 is 2.617093563079834\n",
            " accuracy in epoch 97 after steps 0 is: 0.09948000311851501\n",
            " Loss for main model3 in epoch 97 after steps 0 is: 3.7204766273498535\n",
            "loss after epoch 97 is 2.925969123840332\n",
            " accuracy in epoch 98 after steps 0 is: 0.09882000088691711\n",
            " Loss for main model3 in epoch 98 after steps 0 is: 2.82045578956604\n",
            "loss after epoch 98 is 3.1855990886688232\n",
            " accuracy in epoch 99 after steps 0 is: 0.09888000041246414\n",
            " Loss for main model3 in epoch 99 after steps 0 is: 3.0576822757720947\n",
            "loss after epoch 99 is 2.881138324737549\n",
            "final training accuracy is 0.0983058288693428\n",
            "test accuracy is 0.10300000011920929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxxBxZjlFxSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}